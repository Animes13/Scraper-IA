name: Scraper-IA Workflow

on:
  workflow_dispatch:   # Permite rodar manualmente
  schedule:
    - cron: '0 2 * * *'  # Executa todo dia às 02:00 UTC (ajuste se quiser)

jobs:
  run_scraper_ia:
    runs-on: ubuntu-latest

    env:
      GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}

    steps:
      # 1️⃣ Checkout do repo
      - name: Checkout
        uses: actions/checkout@v3

      # 2️⃣ Instalar Python e dependências
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Instalar dependências
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install google-genai  # ⚡ pacote atualizado
          pip install beautifulsoup4 requests

      # 3️⃣ Criar pastas necessárias
      - name: Criar pastas
        run: |
          mkdir -p HTML
          mkdir -p rules
          mkdir -p data

      # 4️⃣ Rodar a IA para gerar regras adaptativas
      - name: Rodar Gemini IA
        run: |
          python ia/gemini_scraper_ia.py

      # 5️⃣ Rodar o scraper para baixar episódios e gerar JSON
      - name: Rodar Scraper de todos os animes
        run: |
          python scraper/extract_all_animes.py

      # 6️⃣ Commit automático das alterações (HTML, rules, data)
      - name: Commit & Push
        run: |
          git config --local user.name "github-actions[bot]"
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git add HTML rules data
          git diff --cached --quiet || git commit -m "Atualização automática: HTML, regras e JSON"
          git push origin HEAD:main
